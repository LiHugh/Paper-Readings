# [Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning](https://papers.nips.cc/paper/2020/file/f5f3b8d720f34ebebceb7765e447268b-Paper.pdf)
Their code is available at https://github.com/trzhang0116/HRAC.
## Motivation
Distant subgoals can be substituted by closer subgoals, as long as they drive the low-level to move towards the same “direction”. By reducing the action space of the
high-level, the learning efficiency of both the high-level and the low-level can be improved: for the high-level, a considerably smaller action space relieves the burden of exploration and value function
approximation; for the low-level, adjacent subgoals provide a stronger learning signal as the agent can be intrinsically rewarded with a higher frequency for reaching these subgoals.


